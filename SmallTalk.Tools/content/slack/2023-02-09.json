[
    {
        "client_msg_id": "0381a008-101b-444a-8982-a6af64dce8f8",
        "type": "message",
        "text": "yeah, I think that'll be the important part",
        "user": "U04N4LBE5K4",
        "ts": "1676004916.171419",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3SO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "yeah, I think that'll be the important part"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T8NQ4486P",
        "user_team": "T8NQ4486P",
        "source_team": "T8NQ4486P",
        "user_profile": {
            "avatar_hash": "c5f48bf79e05",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-05\/4765375549041_c5f48bf79e05f594269b_72.png",
            "first_name": "Chris",
            "real_name": "Chris",
            "display_name": "Chris",
            "team": "T8NQ4486P",
            "name": "christopher.j.donlan",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1675747412.633829",
        "parent_user_id": "U8PN87H1U"
    },
    {
        "type": "message",
        "subtype": "thread_broadcast",
        "text": "got F-score results w\/out a rolling ML model.  This means that they come with two qualifications that could go either way:\n\n1. the model is trained on all the data, so it is a global model.  That means it is probably weaker than a model trained on the last hour or day of data. \n2. the model is tested on all of the data -- no holdout. \n    a. but it is a markov model\n    b. I normalized everything\n    c. and there4 many rows are going to be similar -- train test results should not be too divergent\nSo, could go either way.  I have to implement a proper validation, but that'll have to be tmrw.\n\nIn the meantime, the results are promising:\n\n```{\n  \"results\": [\n    {\n      \"offset\": 1,\n      \"fscore_window\": 15,\n      \"abs_diff_avg\": 0.26219665067217857,\n      \"abs_diff_var\": 0.026901707595188142,\n      \"abs_diff_std\": 0.16401740028176323\n    }\n  ]\n}\n\n# things again improve out to 2 hours.  I am training on all the data, so what this is \n# telling us is that behavior across 2 hours is essentially a consistent paradigm across time.\n# whereas the tighter window will likely require a model trained on nearby in time.\n# \n# The next step is to do a local model validation across the dataset. \n{\n  \"results\": [\n    {\n      \"offset\": 1,\n      \"fscore_window\": 120,\n      \"abs_diff_avg\": 0.20339403012963536,\n      \"abs_diff_var\": 0.01757120448482316,\n      \"abs_diff_std\": 0.13255642000606066\n    }\n  ]\n}```",
        "user": "U04N4LBE5K4",
        "ts": "1676007992.824299",
        "thread_ts": "1675747412.633829",
        "root": {
            "client_msg_id": "B0514B93-FE96-4D06-A11C-DDEC40DBB17F",
            "type": "message",
            "text": "Do you mean derivatives in the calculus sense?",
            "user": "U8PN87H1U",
            "ts": "1675747412.633829",
            "blocks": [
                {
                    "type": "rich_text",
                    "block_id": "7uN2G",
                    "elements": [
                        {
                            "type": "rich_text_section",
                            "elements": [
                                {
                                    "type": "text",
                                    "text": "Do you mean derivatives in the calculus sense?"
                                }
                            ]
                        }
                    ]
                }
            ],
            "team": "T8NQ4486P",
            "thread_ts": "1675747412.633829",
            "reply_count": 20,
            "reply_users_count": 2,
            "latest_reply": "1676159228.970479",
            "reply_users": [
                "U04N4LBE5K4",
                "U8PN87H1U"
            ],
            "replies": [
                {
                    "user": "U04N4LBE5K4",
                    "ts": "1675751728.050959"
                },
                {
                    "user": "U04N4LBE5K4",
                    "ts": "1675751786.483679"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675797884.329509"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675798274.543789"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675798359.638549"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675798491.370719"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675798565.451589"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675798822.698799"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675798921.958459"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675798963.660359"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675799213.799359"
                },
                {
                    "user": "U04N4LBE5K4",
                    "ts": "1675897660.809909"
                },
                {
                    "user": "U04N4LBE5K4",
                    "ts": "1675897852.327009"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675906434.187729"
                },
                {
                    "user": "U8PN87H1U",
                    "ts": "1675907540.008679"
                },
                {
                    "user": "U04N4LBE5K4",
                    "ts": "1676004916.171419"
                },
                {
                    "user": "U04N4LBE5K4",
                    "ts": "1676007992.824299"
                },
                {
                    "user": "U04N4LBE5K4",
                    "ts": "1676008539.541319"
                },
                {
                    "user": "U04N4LBE5K4",
                    "ts": "1676008686.753719"
                },
                {
                    "user": "U04N4LBE5K4",
                    "ts": "1676159228.970479"
                }
            ],
            "is_locked": false,
            "subscribed": true,
            "last_read": "1676159228.970479"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "LDDB",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "got F-score results w\/out a rolling ML model.  This means that they come with two qualifications that could go either way:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "the model is trained on all the data, so it is a global model.  That means it is probably weaker than a model trained on the last hour or day of data. "
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "the model is tested on all of the data -- no holdout. "
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "but it is a markov model"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "I normalized everything"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "and there4 many rows are going to be similar -- train test results should not be too divergent"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nSo, could go either way.  I have to implement a proper validation, but that'll have to be tmrw.\n\nIn the meantime, the results are promising:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": "{\n  \"results\": [\n    {\n      \"offset\": 1,\n      \"fscore_window\": 15,\n      \"abs_diff_avg\": 0.26219665067217857,\n      \"abs_diff_var\": 0.026901707595188142,\n      \"abs_diff_std\": 0.16401740028176323\n    }\n  ]\n}\n\n# things again improve out to 2 hours.  I am training on all the data, so what this is \n# telling us is that behavior across 2 hours is essentially a consistent paradigm across time.\n# whereas the tighter window will likely require a model trained on nearby in time.\n# \n# The next step is to do a local model validation across the dataset. \n{\n  \"results\": [\n    {\n      \"offset\": 1,\n      \"fscore_window\": 120,\n      \"abs_diff_avg\": 0.20339403012963536,\n      \"abs_diff_var\": 0.01757120448482316,\n      \"abs_diff_std\": 0.13255642000606066\n    }\n  ]\n}"
                            }
                        ],
                        "border": 0
                    }
                ]
            }
        ],
        "client_msg_id": "9a63f595-117b-49ea-ad68-e6ab3000acf0",
        "edited": {
            "user": "U04N4LBE5K4",
            "ts": "1676009320.000000"
        }
    },
    {
        "client_msg_id": "f7fabf6f-92a8-4f92-b101-68e82b1b17cb",
        "type": "message",
        "text": "I think we can go ahead and start thinking about simming the F-score analysis.  Once I have the validation in place, I'll reframe it as a classification problem and maybe there'll be another trick or two.\n\nI'll also have time to implement a rolling model that incorporates multiple predictions -- which I've talked about a few times -- but that'll be complicated to implement at 1 am w\/ cranky baby.",
        "user": "U04N4LBE5K4",
        "ts": "1676008113.228659",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Ir9r5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think we can go ahead and start thinking about simming the F-score analysis.  Once I have the validation in place, I'll reframe it as a classification problem and maybe there'll be another trick or two.\n\nI'll also have time to implement a rolling model that incorporates multiple predictions -- which I've talked about a few times -- but that'll be complicated to implement at 1 am w\/ cranky baby."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T8NQ4486P",
        "user_team": "T8NQ4486P",
        "source_team": "T8NQ4486P",
        "user_profile": {
            "avatar_hash": "c5f48bf79e05",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-05\/4765375549041_c5f48bf79e05f594269b_72.png",
            "first_name": "Chris",
            "real_name": "Chris",
            "display_name": "Chris",
            "team": "T8NQ4486P",
            "name": "christopher.j.donlan",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1676008113.228659",
        "reply_count": 1,
        "reply_users_count": 1,
        "latest_reply": "1676009525.059109",
        "reply_users": [
            "U04N4LBE5K4"
        ],
        "replies": [
            {
                "user": "U04N4LBE5K4",
                "ts": "1676009525.059109"
            }
        ],
        "is_locked": false,
        "subscribed": false
    },
    {
        "client_msg_id": "d8db673f-baeb-4c4f-b513-e9a59a0cbb02",
        "type": "message",
        "text": "The results say that the time independent regression (markov model) is, on average, 0.26 off on the F score w\/ a std dev of 0.16.  That means 68.2% of the time the regression is w\/in .26 +\/- .16 of the actual, or .42.\n\nThat might not sound good right now, but it is enough. Once I start to unpack the tricks, it'll tighten up.  Three things are going to drive that:\n\n1. Reframing as a classification problem\n2. Leveraging confidence techniques\n3. Training on local data &lt;- this is the biggest one\n    a. Doesn't make sense to train on all 219,000 points\n    b. A lot of the points will be the same w\/ different outputs\n    c. Very counter productive\n(3) also involves real work to lay down the code necessary to keep it all clean (no future leak), etc.",
        "user": "U04N4LBE5K4",
        "ts": "1676008539.541319",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "St4",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The results say that the time independent regression (markov model) is, on average, 0.26 off on the F score w\/ a std dev of 0.16.  That means 68.2% of the time the regression is w\/in .26 +\/- .16 of the actual, or .42.\n\nThat might not sound good right now, but it is enough. Once I start to unpack the tricks, it'll tighten up.  Three things are going to drive that:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Reframing as a classification problem"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Leveraging confidence techniques"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Training on local data <- this is the biggest one"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Doesn't make sense to train on all 219,000 points"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "A lot of the points will be the same w\/ different outputs"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Very counter productive"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n(3) also involves real work to lay down the code necessary to keep it all clean (no future leak), etc."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T8NQ4486P",
        "user_team": "T8NQ4486P",
        "source_team": "T8NQ4486P",
        "user_profile": {
            "avatar_hash": "c5f48bf79e05",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-05\/4765375549041_c5f48bf79e05f594269b_72.png",
            "first_name": "Chris",
            "real_name": "Chris",
            "display_name": "Chris",
            "team": "T8NQ4486P",
            "name": "christopher.j.donlan",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1675747412.633829",
        "parent_user_id": "U8PN87H1U"
    },
    {
        "client_msg_id": "6dce335c-f890-4ad1-bbd9-d61f6531d8e1",
        "type": "message",
        "text": "and when we get finished w\/ all the tricks that come w\/ (3), introducing the exotic features, transforms, and techniques like the wavelet or non-naive bayes will get us over the hump.\n\nBut, that is salt and pepper.  Gotta get the steak on the grill, so to speak.",
        "user": "U04N4LBE5K4",
        "ts": "1676008686.753719",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "IIN2F",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "and when we get finished w\/ all the tricks that come w\/ (3), introducing the exotic features, transforms, and techniques like the wavelet or non-naive bayes will get us over the hump.\n\nBut, that is salt and pepper.  Gotta get the steak on the grill, so to speak."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T8NQ4486P",
        "user_team": "T8NQ4486P",
        "source_team": "T8NQ4486P",
        "user_profile": {
            "avatar_hash": "c5f48bf79e05",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-05\/4765375549041_c5f48bf79e05f594269b_72.png",
            "first_name": "Chris",
            "real_name": "Chris",
            "display_name": "Chris",
            "team": "T8NQ4486P",
            "name": "christopher.j.donlan",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "U04N4LBE5K4",
            "ts": "1676008778.000000"
        },
        "thread_ts": "1675747412.633829",
        "parent_user_id": "U8PN87H1U"
    },
    {
        "client_msg_id": "c27bdd24-e2af-41d4-8d96-55c15a716572",
        "type": "message",
        "text": "From a simming perspective, the most likely way this is going to work is [*stage 1*] a rolling model trained on some rolling window of size ranging from [100, 10000] minutes (or several models with different ranges) every minute [*var 1*].\n\nThey get trained, they make their F-score predictions at the fixed interval or multiple F-score intervals [*var 2*].\n\nSo, at the conceptual level, it'll be a first-in-first-dropped queue on the ML side, where rows get pushed in...and predictions come out.  [*stage 2*] Different models have different sized queues, and there is a synthesis of predictions as a downstream step.\n\n[*var 3*] Retraining every N minutes (ideally, N=1, but this'll be the cost sensitive parameter).\n\nNot sure what the cheapest way to implement this'll be.\n\n(DNN is DOA -- no way to retrain many rolling DNNs like that)",
        "user": "U04N4LBE5K4",
        "ts": "1676009525.059109",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Uyv",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "From a simming perspective, the most likely way this is going to work is ["
                            },
                            {
                                "type": "text",
                                "text": "stage 1",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "] a rolling model trained on some rolling window of size ranging from [100, 10000] minutes (or several models with different ranges) every minute ["
                            },
                            {
                                "type": "text",
                                "text": "var 1",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "].\n\nThey get trained, they make their F-score predictions at the fixed interval or multiple F-score intervals ["
                            },
                            {
                                "type": "text",
                                "text": "var 2",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "].\n\nSo, at the conceptual level, it'll be a first-in-first-dropped queue on the ML side, where rows get pushed in...and predictions come out.  ["
                            },
                            {
                                "type": "text",
                                "text": "stage 2",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "] Different models have different sized queues, and there is a synthesis of predictions as a downstream step.\n\n["
                            },
                            {
                                "type": "text",
                                "text": "var 3",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "] Retraining every N minutes (ideally, N=1, but this'll be the cost sensitive parameter).\n\nNot sure what the cheapest way to implement this'll be.\n\n(DNN is DOA -- no way to retrain many rolling DNNs like that)"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T8NQ4486P",
        "user_team": "T8NQ4486P",
        "source_team": "T8NQ4486P",
        "user_profile": {
            "avatar_hash": "c5f48bf79e05",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-02-05\/4765375549041_c5f48bf79e05f594269b_72.png",
            "first_name": "Chris",
            "real_name": "Chris",
            "display_name": "Chris",
            "team": "T8NQ4486P",
            "name": "christopher.j.donlan",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "U04N4LBE5K4",
            "ts": "1676010167.000000"
        },
        "thread_ts": "1676008113.228659",
        "parent_user_id": "U04N4LBE5K4"
    }
]